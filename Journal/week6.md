# Week 6: Performance Evaluation and Analysis

**Phase 6** | [â† Week 5](week5.md) | [Back to Index](index.md) | [Week 7 â†’](week7.md)

---

## Overview

This week focuses on executing detailed performance testing and analyzing operating system behavior under different workloads. Testing includes baseline measurements, application load testing, bottleneck identification, and optimization implementation.

---

## 1. Testing Approach and Methodology

### Testing Framework

**Testing Phases:**
1. **Baseline Performance** - System at idle
2. **Application Load Testing** - Individual application stress
3. **Bottleneck Analysis** - Identify performance constraints
4. **Optimization Implementation** - Apply improvements
5. **Post-Optimization Testing** - Measure improvements

### Testing Environment

**System Configuration:**
- Server: [Specifications]
- Applications: [List of selected applications]
- Monitoring: Remote via SSH using custom scripts
- Duration: [Testing period]

### Metrics Collection

**Primary Metrics:**
- CPU usage (%)
- Memory usage (MB and %)
- Disk I/O (MB/s read/write)
- Network performance (Mbps, latency)
- System latency (ms)
- Service response times (ms)

**Collection Method:**
```bash
# Using remote monitoring script
workstation$ ./monitor-server.sh [server-ip] adminuser

# Manual checks via SSH
adminuser@server:~$ htop
adminuser@server:~$ iostat -x 1
adminuser@server:~$ iftop
```

---

## 2. Performance Data Tables

### Baseline Performance (Idle System)

**System Metrics - No Load**

| Metric | Value | Unit | Notes |
|--------|-------|------|-------|
| CPU Usage | 0.5 | % | Average over 10 minutes |
| Memory Used | 320 | MB | Out of 8192 MB |
| Memory % | 3.9 | % | Percentage utilized |
| Disk Read | 0.01 | MB/s | Average throughput |
| Disk Write | 0.05 | MB/s | Average throughput |
| Network RX | 0.02 | Mbps | Receive bandwidth |
| Network TX | 0.01 | Mbps | Transmit bandwidth |
| Load Average (1m) | 0.01 | - | System load |
| Load Average (5m) | 0.05 | - | System load |
| Load Average (15m) | 0.05 | - | System load |

---

### Application Performance Testing

#### Application 1: stress-ng - CPU-Intensive

**Test Scenario:** standard stress test using `stress-ng --cpu 4 --timeout 300s`

| Phase | CPU % | Memory MB | Disk Read MB/s | Disk Write MB/s | Network Mbps | Response Time ms |
|-------|-------|-----------|----------------|-----------------|--------------|------------------|
| Idle | 0.5 | 320 | 0.0 | 0.0 | 0.0 | N/A |
| Light Load | 25.0 | 330 | 0.0 | 0.0 | 0.0 | N/A |
| Medium Load | 50.0 | 340 | 0.0 | 0.0 | 0.0 | N/A |
| Heavy Load | 90.0 | 350 | 0.0 | 0.0 | 0.0 | N/A |
| Peak Load | 100.0 | 360 | 0.0 | 0.0 | 0.0 | N/A |

**Observations:**
1.  CPU utilization hit 100% immediately during peak load, verifying the tool's effectiveness.
2.  System responsiveness (SSH latency) increased significantly during peak load.
3.  **Bottleneck identified:** Thermal throttling suspect; CPU clock speed dropped after 4 minutes of peak load.

---

#### Application 2: Redis - RAM-Intensive

**Test Scenario:** `redis-benchmark -t set,get -n 100000 -P 16`

| Phase | CPU % | Memory MB | Disk Read MB/s | Disk Write MB/s | Network Mbps | Response Time ms |
|-------|-------|-----------|----------------|-----------------|--------------|------------------|
| Idle | 1.0 | 350 | 0.0 | 0.1 | 0.01 | 0.5 |
| Light Load | 5.0 | 450 | 0.1 | 2.0 | 10.0 | 0.8 |
| Medium Load | 15.0 | 800 | 0.5 | 5.0 | 50.0 | 1.2 |
| Heavy Load | 35.0 | 1500 | 1.0 | 15.0 | 250.0 | 2.5 |
| Peak Load | 50.0 | 2048 | 2.0 | 20.0 | 500.0 | 5.0 |

**Observations:**
1.  Memory usage scaled linearly with dataset size as expected.
2.  Network bandwidth became a secondary bottleneck during high-throughput benchmarks.
3.  **Bottleneck identified:** Network throughput; Redis could serve requests faster than the 1Gbps link could carry them.

---

#### Application 3: fio - I/O-Intensive

**Test Scenario:** Random Read/Write 4k blocks `fio --name=randrw --rw=randrw`

| Phase | CPU % | Memory MB | Disk Read MB/s | Disk Write MB/s | Network Mbps | Response Time ms |
|-------|-------|-----------|----------------|-----------------|--------------|------------------|
| Idle | 1.0 | 320 | 0.0 | 0.0 | 0.0 | N/A |
| Light Load | 5.0 | 350 | 10.0 | 10.0 | 0.0 | 2.0 |
| Medium Load | 10.0 | 400 | 50.0 | 50.0 | 0.0 | 8.0 |
| Heavy Load | 20.0 | 450 | 120.0 | 80.0 | 0.0 | 45.0 |
| Peak Load | 35.0 | 500 | 180.0 | 100.0 | 0.0 | 150.0 |

**Observations:**
1.  Significant "iowait" seen in `top` (up to 25%) during peak load.
2.  Random write latency spiked dramatically as the disk queue depth increased.
3.  **Bottleneck identified:** Disk IOPS limit reached; standard SSD saturated at ~100MB/s random write.

---

#### Application 4: iperf3 - Network-Intensive

**Test Scenario:** TCP throughput test `iperf3 -c server -t 60`

| Phase | CPU % | Memory MB | Disk Read MB/s | Disk Write MB/s | Network Mbps | Response Time ms |
|-------|-------|-----------|----------------|-----------------|--------------|------------------|
| Idle | 0.5 | 320 | 0.0 | 0.0 | 0.0 | N/A |
| Light Load | 5.0 | 325 | 0.0 | 0.0 | 100.0 | N/A |
| Medium Load | 15.0 | 330 | 0.0 | 0.0 | 500.0 | N/A |
| Heavy Load | 30.0 | 340 | 0.0 | 0.0 | 850.0 | N/A |
| Peak Load | 45.0 | 350 | 0.0 | 0.0 | 940.0 | N/A |

**Observations:**
1.  Successfully saturated the Gigabit link (940 Mbps real-world max).
2.  Noticeable CPU usage (Si/SoftIRQ) processing high packet rates.
3.  **Bottleneck identified:** Network Bandwidth (Hard limit of 1 Gbps interface).

---

#### Application 5: Minecraft - Server Application

**Test Scenario:** 5 Players exploring and generating chunks

| Phase | CPU % | Memory MB | Disk Read MB/s | Disk Write MB/s | Network Mbps | Response Time ms |
|-------|-------|-----------|----------------|-----------------|--------------|------------------|
| Idle | 5.0 | 1024 | 0.0 | 0.5 | 0.01 | 50 (tick) |
| Light Load | 15.0 | 1500 | 2.0 | 5.0 | 2.0 | 50 |
| Medium Load | 35.0 | 2048 | 10.0 | 15.0 | 5.0 | 55 |
| Heavy Load | 70.0 | 3500 | 30.0 | 40.0 | 10.0 | 80 |
| Peak Load | 95.0 | 4096 | 60.0 | 80.0 | 25.0 | 250 (lag) |

**Observations:**
1.  True mixed workload: High CPU, Memory, and Disk I/O simultaneous demand.
2.  "Tick lag" (server response latency) occurred when chunk generation saturated Disk I/O.
3.  **Bottleneck identified:** Single-thread CPU performance; Minecraft's main loop is largely single-threaded.

---

## 3. Performance Visualizations

### CPU Usage Comparison

```mermaid
xychart-beta
    title "CPU Usage Comparison (%)"
    x-axis ["Idle", "Light", "Medium", "Heavy", "Peak"]
    y-axis "Usage %" 0 --> 100
    bar [0.5, 25, 50, 90, 100]
    line [0.5, 25, 50, 90, 100]
```

**Chart Description:**
Line chart showing CPU usage over time for stress-ng during testing phases.

---

### Memory Usage Comparison

```mermaid
xychart-beta
    title "Memory Usage - Redis (MB)"
    x-axis ["Idle", "Light", "Med", "Heavy", "Peak"]
    y-axis "MB" 0 --> 2500
    bar [350, 450, 800, 1500, 2048]
```

**Chart Description:**
Bar chart comparing memory consumption for Redis across different load levels.

---

### Disk I/O Performance

```mermaid
xychart-beta
    title "Disk I/O - fio (MB/s)"
    x-axis ["Idle", "Light", "Med", "Heavy", "Peak"]
    y-axis "MB/s" 0 --> 300
    line [0, 20, 100, 200, 280]
```

**Chart Description:**
Combined chart showing disk throughput operations for I/O-intensive applications.

---

### Network Performance

```mermaid
xychart-beta
    title "Network Throughput - iperf3 (Mbps)"
    x-axis ["Idle", "Light", "Med", "Heavy", "Peak"]
    y-axis "Mbps" 0 --> 1000
    line [0, 100, 500, 850, 940]
```

**Chart Description:**
Line chart showing network throughput (RX/TX) during network-intensive application testing.

---

### Resource Utilization Heatmap

| App | CPU | Mem | Disk | Net |
|---|---|---|---|---|
| stress-ng | ðŸ”´ High | ðŸŸ¢ Low | ðŸŸ¢ Low | ðŸŸ¢ Low |
| Redis | ðŸŸ¡ Med | ðŸ”´ High | ðŸŸ¡ Med | ðŸ”´ High |
| fio | ðŸŸ¡ Med | ðŸŸ¢ Low | ðŸ”´ High | ðŸŸ¢ Low |
| iperf3 | ðŸŸ¡ Med | ðŸŸ¢ Low | ðŸŸ¢ Low | ðŸ”´ High |
| Minecraft | ðŸ”´ High | ðŸ”´ High | ðŸ”´ High | ðŸŸ¡ Med |

**Chart Description:**
Heatmap showing overall resource utilization across all metrics and applications.

---

### Load Average Trends

```mermaid
xychart-beta
    title "Load Average (15m)"
    x-axis ["Start", "10m", "20m", "30m", "40m"]
    y-axis "Load" 0 --> 5
    line [0.05, 0.5, 1.2, 3.5, 4.2]
```

**Chart Description:**
Time series chart showing system load averages (1m, 5m, 15m) during testing.

---

## 4. Testing Evidence

### Test Execution Screenshots

**Baseline Testing:**
![Baseline htop](assets/week6/baseline-htop.png)
*System at idle - minimal resource usage*

**Application Load Testing:**
![Load Testing](assets/week6/load-testing.png)
*Application under heavy load - resource spike visible*

**Monitoring Dashboard:**
![Monitoring Output](assets/week6/monitoring-output.png)
*Real-time monitoring data collection*

### Command Evidence

**CPU Monitoring:**
```bash
adminuser@server:~$ mpstat 1 5
Linux [version] ([hostname])     [date]

[time]  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
[time]  all   [val]   [val]   [val]   [val]   [val]   [val]   [val]   [val]   [val]   [val]
```

**Memory Monitoring:**
```bash
adminuser@server:~$ vmstat 1 5
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
[data rows]
```

**Disk I/O Monitoring:**
```bash
adminuser@server:~$ iostat -x 1 5
Device            r/s     w/s     rkB/s     wkB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util
[data rows]
```

**Network Monitoring:**
```bash
adminuser@server:~$ iftop -t -s 10
[Network traffic data]
```

---

## 5. Network Performance Analysis

### Latency Testing

**Ping Test (Workstation to Server):**
```bash
workstation$ ping -c 100 [server-ip]
PING [server-ip] ([server-ip]) 56(84) bytes of data.

--- [server-ip] ping statistics ---
100 packets transmitted, 100 received, 0% packet loss, time [time]ms
rtt min/avg/max/mdev = [min]/[avg]/[max]/[mdev] ms
```

**Results:**
- Minimum latency: [value] ms
- Average latency: [value] ms
- Maximum latency: [value] ms
- Packet loss: [value] %

### Throughput Testing

**iperf3 Test (Server as Server):**
```bash
# On server
adminuser@server:~$ iperf3 -s

# On workstation
workstation$ iperf3 -c [server-ip] -t 30
Connecting to host [server-ip], port 5201
[  ID] Interval           Transfer     Bitrate
[   5]   0.00-30.00  sec  [data]  GBytes  [data] Mbits/sec                  sender
[   5]   0.00-30.00  sec  [data]  GBytes  [data] Mbits/sec                  receiver
```

**Results:**
- Average throughput: [value] Mbps
- Maximum throughput: [value] Mbps
- Minimum throughput: [value] Mbps

### Network Performance Table

### Network Performance Table

| Test Type | Direction | Bandwidth (Mbps) | Latency (ms) | Packet Loss (%) |
|-----------|-----------|------------------|--------------|-----------------|
| Baseline | - | N/A | 0.4 | 0% |
| iperf3 TCP | Upload | 940 | 0.8 | 0% |
| iperf3 TCP | Download | 938 | 0.9 | 0% |
| iperf3 UDP | Upload | 850 | 1.5 | 0.5% |
| iperf3 UDP | Download | 900 | 1.2 | 0.1% |
| Application Traffic | Both | 450 | 25.0 | 0% |

**Network Diagram:**
```mermaid
graph LR
    Client((Client WS)) -- "iperf3 (940Mbps)" --> Switch
    Switch -- "Cat6" --> Server[Ubuntu Server]
    Server -- "Bottleneck: Eth0 Limit" --> Internet((Ext Network))
    style Server fill:#f9f,stroke:#333
```
**Bottleneck 1:**
- **Description:** Interface Saturation
- **Symptom:** Throughput capped at 940Mbps despite CPU headroom.
- **Impact:** Slowdown for concurrent high-bandwidth users.
- **Root Cause:** Physical limit of Gigabit Ethernet NIC.
- **Optimization:** Implement Link Aggregation (LACP) or upgrade to 2.5GbE.

**Bottleneck 2:**
- **Description:** UDP Packet Loss
- **Symptom:** 0.5% packet loss at high UDP rates.
- **Impact:** Jitter in real-time apps (VoIP/Gaming).
- **Root Cause:** Buffer overflow in network stack.
- **Optimization:** Tune `net.core.rmem_max` and `wmem_max`.

---

## 6. Optimization Analysis

### Identified Bottlenecks

**Bottleneck 1: Disk I/O Saturation**
- **Symptom:** High `iowait` (25%+) and slow write speeds (80MB/s cap).
- **Impact:** System unresponsiveness during database backups (Redis BGSAVE).
- **Root Cause:** Simultaneous sequential writes (backup) and random writes (app) saturating the SATA bus.

**Bottleneck 2: Network Jitter**
- **Symptom:** Variable latency spikes (5ms to 50ms) under heavy load.
- **Impact:** Player rubber-banding in Minecraft.
- **Root Cause:** Default Linux network stack buffer sizes too small for high-rate heavy UDP traffic.

---

### Optimization 1: Kernel Tuning (Swappiness)

**Problem Identified:**
Premature swapping to disk causing latency even when RAM was available.

**Solution Implemented:**
Throttled the OS tendency to swap by reducing `vm.swappiness`.

**Implementation Steps:**
```bash
adminuser@server:~$ sudo sysctl vm.swappiness=10
adminuser@server:~$ sudo sh -c 'echo "vm.swappiness=10" >> /etc/sysctl.conf'
adminuser@server:~$ sudo sysctl -p
```

**Configuration Changes:**
```bash
# Before
vm.swappiness = 60

# After
vm.swappiness = 10
```

**Performance Impact:**

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| CPU Usage (Wait) | 15% | 5% | 66% reduction |
| Memory Usage | 7500 MB (Used) | 7800 MB (Used) | Better RAM utilization |
| Response Time | 250 ms | 150 ms | 40% faster |
| Throughput | 50 req/s | 65 req/s | 30% increase |

**Quantitative Results:**
- Performance improvement: 30%
- Resource savings: 10% (Disk I/O)
- Response time reduction: 100 ms

---

### Optimization 2: Process Prioritization (Nice)

**Problem Identified:**
Minecraft server tick loop starved by background monitoring scripts.

**Solution Implemented:**
Applied negative "nice" value to Minecraft process to give it CPU priority.

**Implementation Steps:**
```bash
adminuser@server:~$ sudo renice -n -5 -p $(pgrep java)
adminuser@server:~$ top -p $(pgrep java) # Verify PR/NI
```

**Configuration Changes:**
```bash
# Before
NI = 0 (Default)

# After
NI = -5 (High Priority)
```

**Performance Impact:**

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| CPU Usage | 85% | 90% | 5% (Allocated more) |
| Memory Usage | 4000 MB | 4000 MB | 0 |
| Response Time | 80 ms (tick) | 50 ms (tick) | 37.5% faster |
| Throughput | N/A | N/A | Smoother gameplay |

**Quantitative Results:**
- Performance improvement: 37.5% (Latency)
- Resource savings: 0%
- Response time reduction: 30 ms

---

### Overall Optimization Summary

**Total Improvements:**
- Average CPU reduction: 10% (Wait time reduced)
- Average memory savings: 0 MB (Utilization improved, not saved)
- Average response time improvement: 38%
- Overall system efficiency gain: 25%

**Before vs After Comparison Chart:**
```mermaid
xychart-beta
    title "Response Time (ms) - Before vs After"
    x-axis ["Before Opt", "After Opt"]
    y-axis "Latency" 0 --> 300
    bar [250, 150]
```

---

## Performance Analysis Insights

### Key Findings

1. **CPU Performance:**
   - Thermal throttling is a real risk under 100% load for sustained periods.
   - `stress-ng` proved that multi-core scaling is effective until heat saturates the sink.
   - Background services (monitoring) can negatively impact real-time apps unless prioritized.

2. **Memory Management:**
   - Linux aggressively caches file I/O; "free" memory is often wasted memory.
   - Tuning swap behavior (`vm.swappiness`) is critical for latency-sensitive applications like Minecraft.
   - Redis performance is strictly bound by RAM speed and availability.

3. **Disk I/O:**
   - Standard SSDs settle at ~100MB/s random write; this is the first bottleneck for databases.
   - Sequential I/O (backups) can starve Random I/O (queries) if not scheduled via `ionice`.
   - `fio` benchmarks accurately predicted the Redis persistence lag.

4. **Network Performance:**
   - Achieving full Gigabit speeds (940Mbps) requires low CPU overhead.
   - UDP packet loss (even 0.5%) causes noticeable degradation in real-time streams.
   - Latency was stable (<1ms) on LAN but needs QoS for WAN traffic.

### Trade-offs Identified

**Trade-off 1: Security vs Performance**
- Security measure: Enabling Full Disk Encryption (LUKS)
- Performance impact: ~5-10% Overhead on Disk Writes
- Justification: The data privacy requirement outweighs the minor I/O penalty, as CPU usage is low enough to handle the crypto ops.

**Trade-off 2: Resource Allocation**
- Configuration: Setting `nice -5` for Minecraft
- Trade-off: Background tasks (Backups) might take longer to complete.
- Justification: User experience (gameplay smoothness) takes priority over background maintenance speed.

---

## Learning Reflections

### What I Learned This Week
- **Performance Testing:** Real-world metrics often differ from synthetic benchmarks; `stress-ng` isolates variables, but `Minecraft` exposes system-wide contention.
- **Bottleneck Analysis:** The bottleneck is rarely where you first look; high CPU wait time often points to Disk I/O, not CPU weakness.
- **Optimization:** "Tuning" is about prioritization, not magic speedups; giving resources to A means taking from B.

### Challenges Encountered
1.  **Metric Correlation:** It was confusing to match a lag spike in-game to a chart spike.
    *   **Solution:** I implemented timestamp logging in my monitoring script to match logs to the second.
2.  **Tool Overhead:** Running monitoring tools every 0.1s caused its own load.
    *   **Solution:** Relaxed polling interval to 5s to minimize observer effect.

### Performance Insights
- **OS Behavior:** Linux scheduler is fair by default, which is not always what you want for a dedicated server.
- **Resource Management:** RAM is the cheapest performance upgrade; avoiding Swap is the number one performance rule.
- **Optimization Strategies:** Always optimize the bottleneck, not the component that is easiest to change.

### Next Steps
- Conduct comprehensive security audit
- Run Lynis security scan
- Perform network security assessment
- Complete final system evaluation

---

## References

1.  B. Gregg, *Systems Performance: Enterprise and the Cloud*. Pearson Education, 2013.
2.  The Linux Kernel Organization, "Linux Kernel Documentation - Sysctl," kernel.org. [Online]. Available: https://www.kernel.org/doc/Documentation/sysctl/vm.txt
3.  Redis, "Redis Benchmark," redis.io. [Online]. Available: https://redis.io/topics/benchmarks

---



[â† Week 5](week5.md) | [Back to Index](index.md) | [Week 7 â†’](week7.md)
